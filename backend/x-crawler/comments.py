import asyncio
import csv
import re
from playwright.async_api import async_playwright

VIDEO_URL = "https://www.youtube.com/watch?v=1MWQIItK90Y"  # æ›¿æ¢ä¸ºä½ çš„è§†é¢‘é“¾æ¥

def get_sortable_likes(likes: str) -> float:
    likes = likes.replace(",", "").strip()
    multiplier = 1
    if likes.endswith("K"):
        multiplier = 1_000
        likes = likes[:-1]
    elif likes.endswith("M"):
        multiplier = 1_000_000
        likes = likes[:-1]
    try:
        return float(likes) * multiplier
    except:
        return 0

async def scroll_to_comments(page):
    print("ğŸ” æ­£åœ¨æ»šåŠ¨åˆ°è¯„è®ºåŒºåŸŸ...")
    await page.wait_for_selector("#comments", timeout=10000)
    comments_section = await page.query_selector("#comments")
    await comments_section.scroll_into_view_if_needed()
    await asyncio.sleep(3)  # ç­‰å¾…åŠ è½½

async def extract_comments(page):
    comments_data = []
    comment_elements = await page.query_selector_all('#contents #comment')

    print(f"ğŸ“ æ‰¾åˆ° {len(comment_elements)} æ¡åŸå§‹è¯„è®ºï¼Œå¼€å§‹æå–...")
    for element in comment_elements:
        try:
            text_el = await element.query_selector('#content-text')
            author_el = await element.query_selector('#author-text')
            likes_el = await element.query_selector('#vote-count-middle')

            text = (await text_el.inner_text()).strip()
            author = (await author_el.inner_text()).strip()
            likes = (await likes_el.inner_text()).strip()

            comments_data.append({
                'text': text.replace('\n', ' ').replace('"', '""').replace("'", "''"),
                'author': author.replace('"', '""').replace("'", "''"),
                'likes': likes
            })
        except Exception as e:
            print(f"âš ï¸ è·³è¿‡ä¸€æ¡è¯„è®ºï¼ŒåŸå› : {e}")
            continue
    return comments_data

def save_to_csv(comments, video_title, video_id):
    comments.sort(key=lambda x: get_sortable_likes(x['likes']), reverse=True)
    filename = f"{video_title} [{video_id}].csv"
    with open(filename, "w", newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(["Text", "Author", "Likes"])
        for comment in comments:
            writer.writerow([comment['text'], comment['author'], comment['likes']])
    print(f"âœ… å·²ä¿å­˜è¯„è®ºä¸º CSV: {filename}")

async def main():
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        context = await browser.new_context(viewport={'width': 1280, 'height': 800})
        page = await context.new_page()

        print("ğŸŒ æ‰“å¼€é¡µé¢ä¸­...")
        await page.goto(VIDEO_URL)
        await page.wait_for_selector("#comments", timeout=15000)

        # å…³é—­å¯èƒ½å­˜åœ¨çš„ cookie å¼¹çª—
        try:
            accept_btn = await page.query_selector('button:has-text("Accept")')
            if accept_btn:
                await accept_btn.click()
                print("âœ… å·²ç‚¹å‡» cookie åŒæ„æŒ‰é’®")
        except:
            pass

        # æ»šåŠ¨åˆ°è¯„è®ºæ¨¡å—
        await scroll_to_comments(page)

        # æå–è¯„è®º
        comments = await extract_comments(page)

        # è·å–æ ‡é¢˜ & ID
        video_id_match = re.findall(r'v=([a-zA-Z0-9_-]+)', VIDEO_URL)
        video_id = video_id_match[0] if video_id_match else 'unknown'

        title_raw = await page.title()
        video_title = title_raw.replace(" - YouTube", "").strip()
        video_title = re.sub(r'[^\w\s\-_\.]', '', video_title).strip().replace(" ", "_")

        # ä¿å­˜ä¸º CSV
        save_to_csv(comments, video_title, video_id)

        await browser.close()

asyncio.run(main())
